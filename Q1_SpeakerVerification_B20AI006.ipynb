{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Clone UniSpeech"
      ],
      "metadata": {
        "id": "8NCUnK3Ns5SK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB79k2wbs1Fj",
        "outputId": "68f958cc-c8d6-44b8-d6b9-fdd8b4b341e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'downstreams/speaker_verification'...\n",
            "remote: Enumerating objects: 486, done.\u001b[K\n",
            "remote: Counting objects: 100% (486/486), done.\u001b[K\n",
            "remote: Compressing objects: 100% (431/431), done.\u001b[K\n",
            "remote: Total 486 (delta 72), reused 385 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (486/486), 70.83 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "Updating files: 100% (433/433), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 --branch main https://github.com/microsoft/UniSpeech.git --single-branch downstreams/speaker_verification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd downstreams/speaker_verification/downstreams/speaker_verification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoEWNiQGteLI",
        "outputId": "d998e99d-27c9-4630-be38-e028494bf328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/downstreams/speaker_verification/downstreams/speaker_verification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download Models"
      ],
      "metadata": {
        "id": "PM-xRmIZtNhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models"
      ],
      "metadata": {
        "id": "mLij120utPuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1178eb14-fe62-4464-ddca-fa4829c768b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/downstreams/speaker_verification/downstreams/speaker_verification/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Union\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio._internal import download_url_to_file\n",
        "from torchaudio.datasets.utils import _extract_zip, _load_waveform\n",
        "\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "_ARCHIVE_CONFIGS = {\n",
        "    \"dev\": {\n",
        "        \"archive_name\": \"vox1_dev_wav.zip\",\n",
        "        \"urls\": [\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partaa\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partab\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partac\",\n",
        "            \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_partad\",\n",
        "        ],\n",
        "        \"checksums\": [\n",
        "            \"21ec6ca843659ebc2fdbe04b530baa4f191ad4b0971912672d92c158f32226a0\",\n",
        "            \"311d21e0c8cbf33573a4fce6c80e5a279d80736274b381c394319fc557159a04\",\n",
        "            \"92b64465f2b2a3dc0e4196ae8dd6828cbe9ddd1f089419a11e4cbfe2e1750df0\",\n",
        "            \"00e6190c770b27f27d2a3dd26ee15596b17066b715ac111906861a7d09a211a5\",\n",
        "        ],\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"archive_name\": \"vox1_test_wav.zip\",\n",
        "        \"url\": \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip\",\n",
        "        \"checksum\": \"8de57f347fe22b2c24526e9f444f689ecf5096fc2a92018cf420ff6b5b15eaea\",\n",
        "    },\n",
        "}\n",
        "_IDEN_SPLIT_URL = \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\"\n",
        "_VERI_TEST_URL = \"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\"\n",
        "\n",
        "\n",
        "def _download_extract_wavs(root: str):\n",
        "    for archive in [\"dev\", \"test\"]:\n",
        "        archive_name = _ARCHIVE_CONFIGS[archive][\"archive_name\"]\n",
        "        archive_path = os.path.join(root, archive_name)\n",
        "        # The zip file of dev data is splited to 4 chunks.\n",
        "        # Download and combine them into one file before extraction.\n",
        "        if archive == \"dev\":\n",
        "            urls = _ARCHIVE_CONFIGS[archive][\"urls\"]\n",
        "            checksums = _ARCHIVE_CONFIGS[archive][\"checksums\"]\n",
        "            with open(archive_path, \"wb\") as f:\n",
        "                for url, checksum in zip(urls, checksums):\n",
        "                    file_path = os.path.join(root, os.path.basename(url))\n",
        "                    download_url_to_file(url, file_path, hash_prefix=checksum)\n",
        "                    with open(file_path, \"rb\") as f_split:\n",
        "                        f.write(f_split.read())\n",
        "        else:\n",
        "            url = _ARCHIVE_CONFIGS[archive][\"url\"]\n",
        "            checksum = _ARCHIVE_CONFIGS[archive][\"checksum\"]\n",
        "            download_url_to_file(url, archive_path, hash_prefix=checksum)\n",
        "        _extract_zip(archive_path)\n",
        "\n",
        "\n",
        "def _get_flist(root: str, file_path: str, subset: str) -> List[str]:\n",
        "    f_list = []\n",
        "    if subset == \"train\":\n",
        "        index = 1\n",
        "    elif subset == \"dev\":\n",
        "        index = 2\n",
        "    else:\n",
        "        index = 3\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            id, path = line.split()\n",
        "            if int(id) == index:\n",
        "                f_list.append(path)\n",
        "    return sorted(f_list)\n",
        "\n",
        "\n",
        "def _get_paired_flist(root: str, veri_test_path: str):\n",
        "    f_list = []\n",
        "    with open(veri_test_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            label, path1, path2 = line.split()\n",
        "            f_list.append((label, path1, path2))\n",
        "    return f_list\n",
        "\n",
        "\n",
        "def _get_file_id(file_path: str, _ext_audio: str):\n",
        "    speaker_id, youtube_id, utterance_id = file_path.split(\"/\")[-3:]\n",
        "    utterance_id = utterance_id.replace(_ext_audio, \"\")\n",
        "    file_id = \"-\".join([speaker_id, youtube_id, utterance_id])\n",
        "    return file_id\n",
        "\n",
        "\n",
        "class VoxCeleb1(Dataset):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "    \"\"\"\n",
        "\n",
        "    _ext_audio = \".wav\"\n",
        "\n",
        "    def __init__(self, root: Union[str, Path], download: bool = False) -> None:\n",
        "        # Get string representation of 'root' in case Path object is passed\n",
        "        root = os.fspath(root)\n",
        "        self._path = os.path.join(root, \"wav\")\n",
        "        if not os.path.isdir(self._path):\n",
        "            if not download:\n",
        "                raise RuntimeError(\n",
        "                    f\"Dataset not found at {self._path}. Please set `download=True` to download the dataset.\"\n",
        "                )\n",
        "            _download_extract_wavs(root)\n",
        "\n",
        "    def get_metadata(self, n: int):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, n: int):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class VoxCeleb1Identification(VoxCeleb1):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset for speaker identification task.\n",
        "\n",
        "    Each data sample contains the waveform, sample rate, speaker id, and the file id.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        subset (str, optional): Subset of the dataset to use. Options: [\"train\", \"dev\", \"test\"]. (Default: ``\"train\"``)\n",
        "        meta_url (str, optional): The url of meta file that contains the list of subset labels and file paths.\n",
        "            The format of each row is ``subset file_path\". For example: ``1 id10006/nLEBBc9oIFs/00003.wav``.\n",
        "            ``1``, ``2``, ``3`` mean ``train``, ``dev``, and ``test`` subest, respectively.\n",
        "            (Default: ``\"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt\"``)\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "\n",
        "    Note:\n",
        "        The file structure of `VoxCeleb1Identification` dataset is as follows:\n",
        "\n",
        "        └─ root/\n",
        "\n",
        "         └─ wav/\n",
        "\n",
        "         └─ speaker_id folders\n",
        "\n",
        "        Users who pre-downloaded the ``\"vox1_dev_wav.zip\"`` and ``\"vox1_test_wav.zip\"`` files need to move\n",
        "        the extracted files into the same ``root`` directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, root: Union[str, Path], subset: str = \"train\", meta_url: str = _IDEN_SPLIT_URL, download: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__(root, download)\n",
        "        if subset not in [\"train\", \"dev\", \"test\"]:\n",
        "            raise ValueError(\"`subset` must be one of ['train', 'dev', 'test']\")\n",
        "        # download the iden_split.txt to get the train, dev, test lists.\n",
        "        meta_list_path = os.path.join(root, os.path.basename(meta_url))\n",
        "        if not os.path.exists(meta_list_path):\n",
        "            download_url_to_file(meta_url, meta_list_path)\n",
        "        self._flist = _get_flist(self._path, meta_list_path, subset)\n",
        "\n",
        "    def get_metadata(self, n: int) -> Tuple[str, int, int, str]:\n",
        "        \"\"\"Get metadata for the n-th sample from the dataset. Returns filepath instead of waveform,\n",
        "        but otherwise returns the same fields as :py:func:`__getitem__`.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            str:\n",
        "                Path to audio\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Speaker ID\n",
        "            str:\n",
        "                File ID\n",
        "        \"\"\"\n",
        "        file_path = self._flist[n]\n",
        "        file_id = _get_file_id(file_path, self._ext_audio)\n",
        "        speaker_id = file_id.split(\"-\")[0]\n",
        "        speaker_id = int(speaker_id[3:])\n",
        "        return file_path, SAMPLE_RATE, speaker_id, file_id\n",
        "\n",
        "\n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, int, int, str]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            Tensor:\n",
        "                Waveform\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Speaker ID\n",
        "            str:\n",
        "                File ID\n",
        "        \"\"\"\n",
        "        metadata = self.get_metadata(n)\n",
        "        waveform = _load_waveform(self._path, metadata[0], metadata[1])\n",
        "        return (waveform,) + metadata[1:]\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._flist)\n",
        "\n",
        "\n",
        "\n",
        "class VoxCeleb1Verification(VoxCeleb1):\n",
        "    \"\"\"*VoxCeleb1* :cite:`nagrani2017voxceleb` dataset for speaker verification task.\n",
        "\n",
        "    Each data sample contains a pair of waveforms, sample rate, the label indicating if they are\n",
        "    from the same speaker, and the file ids.\n",
        "\n",
        "    Args:\n",
        "        root (str or Path): Path to the directory where the dataset is found or downloaded.\n",
        "        meta_url (str, optional): The url of meta file that contains a list of utterance pairs\n",
        "            and the corresponding labels. The format of each row is ``label file_path1 file_path2\".\n",
        "            For example: ``1 id10270/x6uYqmx31kE/00001.wav id10270/8jEAjG6SegY/00008.wav``.\n",
        "            ``1`` means the two utterances are from the same speaker, ``0`` means not.\n",
        "            (Default: ``\"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\"``)\n",
        "        download (bool, optional):\n",
        "            Whether to download the dataset if it is not found at root path. (Default: ``False``).\n",
        "\n",
        "    Note:\n",
        "        The file structure of `VoxCeleb1Verification` dataset is as follows:\n",
        "\n",
        "        └─ root/\n",
        "\n",
        "         └─ wav/\n",
        "\n",
        "         └─ speaker_id folders\n",
        "\n",
        "        Users who pre-downloaded the ``\"vox1_dev_wav.zip\"`` and ``\"vox1_test_wav.zip\"`` files need to move\n",
        "        the extracted files into the same ``root`` directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, root: Union[str, Path], meta_url: str = _VERI_TEST_URL, download: bool = False) -> None:\n",
        "        super().__init__(root, download)\n",
        "        # download the veri_test.txt to get the list of training pairs and labels.\n",
        "        meta_list_path = os.path.join(root, os.path.basename(meta_url))\n",
        "        if not os.path.exists(meta_list_path):\n",
        "            download_url_to_file(meta_url, meta_list_path)\n",
        "        self._flist = _get_paired_flist(self._path, meta_list_path)\n",
        "\n",
        "    def get_metadata(self, n: int) -> Tuple[str, str, int, int, str, str]:\n",
        "        \"\"\"Get metadata for the n-th sample from the dataset. Returns filepaths instead of waveforms,\n",
        "        but otherwise returns the same fields as :py:func:`__getitem__`.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            str:\n",
        "                Path to audio file of speaker 1\n",
        "            str:\n",
        "                Path to audio file of speaker 2\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Label\n",
        "            str:\n",
        "                File ID of speaker 1\n",
        "            str:\n",
        "                File ID of speaker 2\n",
        "        \"\"\"\n",
        "        label, file_path_spk1, file_path_spk2 = self._flist[n]\n",
        "        label = int(label)\n",
        "        file_id_spk1 = _get_file_id(file_path_spk1, self._ext_audio)\n",
        "        file_id_spk2 = _get_file_id(file_path_spk2, self._ext_audio)\n",
        "        return file_path_spk1, file_path_spk2, SAMPLE_RATE, label, file_id_spk1, file_id_spk2\n",
        "\n",
        "\n",
        "    def __getitem__(self, n: int) -> Tuple[Tensor, Tensor, int, int, str, str]:\n",
        "        \"\"\"Load the n-th sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            n (int): The index of the sample to be loaded.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            Tensor:\n",
        "                Waveform of speaker 1\n",
        "            Tensor:\n",
        "                Waveform of speaker 2\n",
        "            int:\n",
        "                Sample rate\n",
        "            int:\n",
        "                Label\n",
        "            str:\n",
        "                File ID of speaker 1\n",
        "            str:\n",
        "                File ID of speaker 2\n",
        "        \"\"\"\n",
        "        metadata = self.get_metadata(n)\n",
        "        waveform_spk1 = _load_waveform(self._path, metadata[0], metadata[2])\n",
        "        waveform_spk2 = _load_waveform(self._path, metadata[1], metadata[2])\n",
        "        return (waveform_spk1, waveform_spk2) + metadata[2:]\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._flist)"
      ],
      "metadata": {
        "id": "uZ-6edfsHZUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run Inference"
      ],
      "metadata": {
        "id": "aoK4voaZtQVg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYeIeWEUtSrH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}